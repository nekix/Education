Фильтр Блюма подразумевает, что мы, в целях экономии памяти и ускорения операций проверки наличия элемента, сжимаем данные максимально до вида битового массива. Это не позволяет гарантированно восстановить данные. Многое зависит от внутренних хеш-функций, но в любом случае восстановление исходного множества сводится к перебору значений. Как мне кажется, именно от знаний об ограничениях, накладываемых на данные, передаваемые в фильтр, зависит насколько успешен будет этот процесс.

В случае с отсутствием информации о характере входных данных мы попадаем в ситуацию, когда их потенциальное число оказывается бесконечно большим (как например вариации символов в строке “безгранично”). В таком случае попытка восстановления данных превращается в фактический взлом хешей “тупым” перебором, но не в восстановление исходного множества.

Другая ситуация, когда у нас заранее есть ограниченное множество, элементы которого могут быть переданы в фильтр и мы его знаем (или знаем какие-либо ограничения, налагаемые на данные). В таком случае мы уже можем реализовать алгоритм, который будет проверять наличие элементов этого множества в фильтре и классифицировать их на
•	“эталонные” – которые точно находятся в фильтре и не подвержены коллизиям и ложноположительным срабатываниям;
•	подверженные коллизиям – мы не можем знать точно, есть ли элемент с коллизией во фильтре. Но с высокой вероятностью один из элементов среди элементов с одинаковой коллизией находится в фильтре (если он не подвержен ложноположительному срабатыванию);
•	ложноположительные – мы не можем наверняка знать, есть ли хоть один из этих элементов в фильтре.

Такая классификация открывает возможность дальнейшей обработки данных с использованием дополнительной информации, например о сочетаемости элементов (зависимости), статистических данных и т.д. Ну или как минимум обнаружить элементы, которые точно или с высокой вероятностью есть в фильтре.

В моей реализации как раз происходит классификация данных на вышеперечисленные три категории:
1.	Метод принимает фильтр и данные “кандидаты” на наличие в нем. Подбор этих данных зависит от конкретной ситуации, в тестах я заранее задал 50 строк “кандидатов”, 10 из которых передавал в фильтр размера 32.
2.	В качестве базовой структуры для алгоритма использовался двумерный массив множеств. Каждый индекс соответствует значению соответствующей хеш-функции для элементов в множестве.
3.	На первом этапе происходит проверка срабатывания фильтра на каждое значение кандидат, в случае положительного срабатывания элемент добавляется в базовую структуру.
4.	На втором этапе происходит выделение из базовой структуры элементов с коллизией: если во множестве из базовой структуры более одного элемента, то это значит, что появилась коллизия (в комментарии к методу отдельная сноска, что я считаю коллизией в данном случае).
5.	На третьем этапе из базовой структуры отдельно выделяются элементы с ложноположительными срабатываниями.
6.	На четвертом этапе алгоритма из элементов базовой структуры вычитаются элементы с коллизиями и ложноположительными срабатываниями, результирующее множество становится “эталонным”.
7.	Происходит возврат “эталонных”, подверженных коллизиям и ложноположительных значений из функции.
